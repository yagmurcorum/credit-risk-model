{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06 - Final Pipeline (Credit Risk Model)\n",
        "\n",
        "Bu notebook, kredi risk modeli için **uçtan uca final pipeline akışını** tek bir yerden gösterir:\n",
        "\n",
        "1. Ham verinin okunması (`cs-training.csv`)\n",
        "2. Temel temizlik ve feature engineering (`prepare_training`)\n",
        "3. Eğitim / validasyon bölünmesi (80/20, stratified)\n",
        "4. Final XGBoost modelinin yüklenmesi (`xgboost_credit_risk_final.pkl`)\n",
        "5. Validasyon setinde performans metrikleri (ROC-AUC, Precision, Recall, F1)\n",
        "6. Farklı threshold değerleri ile karar sınırının incelenmesi\n",
        "\n",
        "Not: Aynı akış script olarak `src/pipeline.py` içinde de mevcuttur; bu notebook daha çok yöneticilere hızlıca akışı göstermek içindir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\YAĞMUR\\Masaüstü\\credit-risk-model\n",
            "src var mı?: True\n"
          ]
        }
      ],
      "source": [
        "# 1. Gerekli importlar ve ayarlar\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    precision_recall_fscore_support,\n",
        ")\n",
        "\n",
        "# Notebook içinde proje kökünü bul (cwd üzerinden)\n",
        "CURRENT_DIR = Path.cwd()\n",
        "if (CURRENT_DIR / \"src\").exists():\n",
        "    PROJECT_ROOT = CURRENT_DIR\n",
        "elif (CURRENT_DIR.parent / \"src\").exists():\n",
        "    PROJECT_ROOT = CURRENT_DIR.parent\n",
        "else:\n",
        "    PROJECT_ROOT = CURRENT_DIR\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"src var mı?:\", (PROJECT_ROOT / \"src\").exists())\n",
        "\n",
        "from src.config import RAW_TRAIN, FINAL_MODEL, SEED, DEFAULT_THRESHOLD\n",
        "from src.data_preprocessing import prepare_training\n",
        "from src.predict import _load_artifact, predict_from_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Veri Yükleme ve Problem Özeti\n",
        "\n",
        "- Veri seti: **Give Me Some Credit (Kaggle)**  \n",
        "- Hedef değişken: `SeriousDlqin2yrs` (müşteri 2 yıl içinde defaulta düştü mü? 0/1)  \n",
        "- Sınıf dengesizliği: Default oranı düşük, bu yüzden ROC-AUC ve Recall kritik.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ham veri shape: (150000, 12)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SeriousDlqin2yrs\n",
              "0    0.93316\n",
              "1    0.06684\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2. Ham veriyi yükle ve temel bilgileri göster\n",
        "\n",
        "raw = pd.read_csv(RAW_TRAIN)\n",
        "print(\"Ham veri shape:\", raw.shape)\n",
        "raw[\"SeriousDlqin2yrs\"].value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Temizlik ve Feature Engineering (`prepare_training`)\n",
        "\n",
        "Bu adımda `src.data_preprocessing.prepare_training` fonksiyonu kullanılarak:\n",
        "\n",
        "- Temel temizlik (age==0 düzeltmesi, eksik değer imputasyonu, delinquency cap)\n",
        "- log1p dönüşümleri\n",
        "- Delinquency feature'ları (TotalDelinquency, DelinquencySeverityScore, vb.)\n",
        "- Risk flag'leri (EverDelinquent, Ever90DaysLate, HighDebtFlag, ...)\n",
        "- Binning (AgeBin, IncomeBin, UtilizationBin, DelinqBin)\n",
        "- Domain feature'lar (EffectiveDebtLoad, RealEstateExposure, FinancialStressIndex)\n",
        "- Feature selection (`FINAL_DROP_COLS`)\n",
        "\n",
        "uygulanır ve final eğitim tablosu elde edilir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hazırlanmış veri shape: (150000, 27)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((150000, 26),\n",
              " SeriousDlqin2yrs\n",
              " 0    0.93316\n",
              " 1    0.06684\n",
              " Name: proportion, dtype: float64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3. Temizlik + Feature Engineering uygulama\n",
        "\n",
        "prepared = prepare_training(raw)\n",
        "print(\"Hazırlanmış veri shape:\", prepared.shape)\n",
        "\n",
        "TARGET_COL = \"SeriousDlqin2yrs\"\n",
        "X = prepared.drop(columns=[TARGET_COL])\n",
        "y = prepared[TARGET_COL]\n",
        "\n",
        "X.shape, y.value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Eğitim / Validasyon Bölünmesi\n",
        "\n",
        "Veri, %80 eğitim, %20 validasyon olacak şekilde, sınıf dengesini koruyarak (stratify) ayrılır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (120000, 26)\n",
            "Val shape  : (30000, 26)\n"
          ]
        }
      ],
      "source": [
        "# 4. Train / Validation split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=SEED,\n",
        "    stratify=y,\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Val shape  :\", X_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Final XGBoost Modelinin Yüklenmesi\n",
        "\n",
        "`models/xgboost_credit_risk_final.pkl` içinde:\n",
        "\n",
        "- `model` : Preprocessing + XGBoost pipeline  \n",
        "- `threshold` : Business gereksinimine göre seçilmiş karar eşiği (ör. 0.81)  \n",
        "- `features` : (opsiyonel) Kullanılan feature isimleri  \n",
        "\n",
        "saklanmaktadır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yüklenen model tipi: <class 'sklearn.pipeline.Pipeline'>\n",
            "Kullanılan threshold: 0.81\n"
          ]
        }
      ],
      "source": [
        "# 5. Model artifact'ini yükle\n",
        "\n",
        "artifact = _load_artifact()\n",
        "model = artifact[\"model\"]\n",
        "threshold = artifact.get(\"threshold\", float(DEFAULT_THRESHOLD))\n",
        "\n",
        "print(\"Yüklenen model tipi:\", type(model))\n",
        "print(\"Kullanılan threshold:\", threshold)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Validasyon Setinde Performans Değerlendirmesi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC   : 0.8701\n",
            "Precision : 0.4178\n",
            "Recall    : 0.4753\n",
            "F1-score  : 0.4447\n",
            "Confusion Matrix (TN, FP, FN, TP): [26667  1328  1052   953]\n"
          ]
        }
      ],
      "source": [
        "# 6. Validasyon setinde tahmin ve metrikler\n",
        "\n",
        "# Olasılık tahmini (default olasılığı, sınıf 1)\n",
        "y_val_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Seçilen threshold ile 0/1 karar\n",
        "y_val_pred = (y_val_proba >= threshold).astype(int)\n",
        "\n",
        "roc = roc_auc_score(y_val, y_val_proba)\n",
        "precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
        "recall = recall_score(y_val, y_val_pred, zero_division=0)\n",
        "f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "print(f\"ROC-AUC   : {roc:.4f}\")\n",
        "print(f\"Precision : {precision:.4f}\")\n",
        "print(f\"Recall    : {recall:.4f}\")\n",
        "print(f\"F1-score  : {f1:.4f}\")\n",
        "print(\"Confusion Matrix (TN, FP, FN, TP):\", cm.ravel())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold: 0.50\n",
            "Pozitif oranı (yüksek riskli oranı): 0.246\n",
            "Precision: 0.214\n",
            "Recall   : 0.788\n",
            "F1-score : 0.337\n",
            "----------------------------------------\n",
            "Threshold: 0.70\n",
            "Pozitif oranı (yüksek riskli oranı): 0.115\n",
            "Precision: 0.345\n",
            "Recall   : 0.596\n",
            "F1-score : 0.437\n",
            "----------------------------------------\n",
            "Threshold: 0.81\n",
            "Pozitif oranı (yüksek riskli oranı): 0.076\n",
            "Precision: 0.418\n",
            "Recall   : 0.475\n",
            "F1-score : 0.445\n",
            "----------------------------------------\n",
            "Threshold: 0.90\n",
            "Pozitif oranı (yüksek riskli oranı): 0.036\n",
            "Precision: 0.551\n",
            "Recall   : 0.299\n",
            "F1-score : 0.388\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 7. Farklı threshold değerleri için performans \n",
        "\n",
        "def evaluate_threshold(th: float):\n",
        "    y_pred_tmp = (y_val_proba >= th).astype(int)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_val, y_pred_tmp, average=\"binary\", zero_division=0\n",
        "    )\n",
        "    positive_rate = y_pred_tmp.mean()\n",
        "    print(f\"Threshold: {th:.2f}\")\n",
        "    print(f\"Pozitif oranı (yüksek riskli oranı): {positive_rate:.3f}\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall   : {recall:.3f}\")\n",
        "    print(f\"F1-score : {f1:.3f}\")\n",
        "\n",
        "for th in [0.50, 0.70, float(DEFAULT_THRESHOLD), 0.90]:\n",
        "    evaluate_threshold(th)\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Final Pipeline Özeti\n",
        "\n",
        "Bu notebook'ta kullanılan uçtan uca akış:\n",
        "\n",
        "1. **Data Loading**  \n",
        "   - `cs-training.csv` ham verisi okunur.\n",
        "\n",
        "2. **Preprocessing & Feature Engineering**  \n",
        "   - `prepare_training(df)` ile temizlik, feature engineering ve feature selection uygulanır.  \n",
        "   - Sonuç: 27 feature içeren final tablo.\n",
        "\n",
        "3. **Train / Validation Split**  \n",
        "   - %80 eğitim, %20 validasyon, `SEED=42`, stratified split.\n",
        "\n",
        "4. **Model**  \n",
        "   - XGBoost tabanlı pipeline (`xgboost_credit_risk_final.pkl`).  \n",
        "   - Class imbalance ve regularization ayarları `config.py` ve model parametrelerinde yönetilir.\n",
        "\n",
        "5. **Decision Threshold**  \n",
        "   - Default threshold: 0.81.  \n",
        "   - Threshold, recall ihtiyacına göre ayarlanabilir (örn. riskli müşteri yakalama oranını artırmak için düşürülebilir).\n",
        "\n",
        "6. **Business Alignment**  \n",
        "   - ROC-AUC, Precision, Recall ve F1 metrikleri, bankanın risk iştahına göre değerlendirilir.\n",
        "\n",
        "Bu notebook, `05_xgboost.ipynb` ve `src/pipeline.py` içindeki akışı **tek sayfalık** bir final pipeline görünümü olarak özetler.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
